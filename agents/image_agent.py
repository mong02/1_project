# image_agent.py

import json
import re
import time
import base64  # <-- [ì¤‘ìš”] OpenAI ì´ë¯¸ì§€ ì „ì†¡ì„ ìœ„í•´ í•„ìš”
from typing import List, Dict, Any
from collections import Counter

# [1] í™˜ê²½ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
from openai import OpenAI, RateLimitError
import ollama

# configì—ì„œ ëª¨ë¸ëª…/ëª¨ë“œ ê°€ì ¸ì˜¤ê¸°
from config import (
    MODEL_VISION,
    MODEL_TEXT,
    API_KEY,
    BASE_URL,
    resolve_api_mode,
    normalize_openai_model,
)

# í”„ë¡¬í”„íŠ¸ ë¡œë” ì¶”ê°€
from utils.prompt_loader import load_prompt, render_prompt

# =========================================================
# ğŸ” í™˜ê²½ì„¤ì • ë° ëª¨ë“œ ìë™ ê°ì§€ (í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§)
# =========================================================
# API ëª¨ë“œ ê²°ì • ë¡œì§ (configì™€ ë™ì¼í•œ ê¸°ì¤€)
API_MODE = resolve_api_mode()

# ëª¨ë¸ëª… ì•ˆì „ì¥ì¹˜ (OpenAI ëª¨ë“œì¸ë° ë¡œì»¬ ëª¨ë¸ëª…ì´ë©´ gpt-4oë¡œ ê°•ì œ)
if API_MODE == "openai":
    USE_MODEL_VISION = normalize_openai_model(MODEL_VISION)
    USE_MODEL_TEXT = normalize_openai_model(MODEL_TEXT)
else:
    USE_MODEL_VISION = MODEL_VISION
    USE_MODEL_TEXT = MODEL_TEXT

# =========================================================
# ğŸ¤– í†µí•© í´ë¼ì´ì–¸íŠ¸ (Vision ê¸°ëŠ¥ ë‚´ì¥)
# =========================================================
class UnifiedClient:
    def __init__(self):
        self.mode = API_MODE
        self.client = None
        if self.mode == "openai":
            if not API_KEY:
                 print("âš ï¸ [Warning] OpenAI ëª¨ë“œì´ë‚˜ API Keyê°€ ì—†ìŠµë‹ˆë‹¤. Vision ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    def _retry_openai(self, func):
        """OpenAI Rate Limit ì¬ì‹œë„ ë¡œì§"""
        for i in range(3):
            try: return func()
            except RateLimitError:
                print(f"â³ Rate Limit (Vision). Retrying in {2**(i+1)}s...")
                time.sleep(2**(i+1))
            except Exception as e: raise e
        raise Exception("OpenAI API Retry Failed")

    # [í•µì‹¬] ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜
    def chat_vision(self, prompt: str, image_bytes: bytes) -> str:
        """ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
        if not image_bytes:
            return "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        if self.mode == "openai" and self.client:
            # --- OpenAI Logic (Base64 ì¸ì½”ë”© í•„ìš”) ---
            try:
                # 1. ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜
                base64_image = base64.b64encode(image_bytes).decode('utf-8')
                
                def _call():
                    response = self.client.chat.completions.create(
                        model=USE_MODEL_VISION,
                        messages=[
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    # 2. ì´ë¯¸ì§€ URL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                                ],
                            }
                        ],
                        max_tokens=500,
                    )
                    return response.choices[0].message.content
                return self._retry_openai(_call)
            except Exception as e:
                 return f"OpenAI Vision Error: {str(e)}"

        else:
            # --- Ollama Logic (ë°”ì´íŠ¸ ì§ì ‘ ì „ì†¡ ê°€ëŠ¥) ---
            try:
                response = ollama.chat(
                    model=USE_MODEL_VISION,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt,
                            # OllamaëŠ” images ë¦¬ìŠ¤íŠ¸ì— ë°”ì´ë„ˆë¦¬ë¥¼ ì§ì ‘ ë„£ìŠµë‹ˆë‹¤.
                            "images": [image_bytes],
                        }
                    ],
                )
                return response["message"]["content"]
            except Exception as e:
                return f"Ollama Vision Error: {str(e)} (ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”: {USE_MODEL_VISION})"

    # í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ (ì¢…í•© ë¶„ì„ìš©)
    def chat_text(self, prompt: str, system_role: str = "assistant") -> str:
        if self.mode == "openai" and self.client:
            def _call():
                return self.client.chat.completions.create(
                    model=USE_MODEL_TEXT,
                    messages=[{"role": "system", "content": system_role}, {"role": "user", "content": prompt}],
                    temperature=0.7
                ).choices[0].message.content
            return self._retry_openai(_call)
        else:
            try:
                resp = ollama.chat(
                    model=USE_MODEL_TEXT,
                    messages=[{"role": "system", "content": system_role}, {"role": "user", "content": prompt}],
                    options={"temperature": 0.7}
                )
                return resp['message']['content']
            except Exception as e:
                return f"Ollama Text Error: {str(e)}"

# í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
client = UnifiedClient()

# =========================================================
# ğŸ§¹ í—¬í¼ í•¨ìˆ˜ (íƒœê·¸ ì¶”ì¶œ ë° JSON íŒŒì‹±)
# =========================================================

def _extract_tags_from_text(text: str, k: int = 4) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë¹ˆë„ ê¸°ë°˜ìœ¼ë¡œ íƒœê·¸ ì¶”ì¶œ (ë°±ì—…ìš©)"""
    STOPWORDS = {
        "ì‚¬ì§„", "ì´ë¯¸ì§€", "ì¥ë©´", "ì œí’ˆ", "êµ¬ì„±", "í¬í•¨", "ìˆëŠ”", "ìœ„", "ì•„ë˜", "ì˜†", "ì•", "ë’¤",
        "ê°™ì€", "ìœ„í•´", "ì •ë„", "ë¶€ë¶„", "ì‚¬ìš©", "ê°€ëŠ¥", "ë³´ì„", "ë³´ì´ëŠ”", "ìˆë‹¤", "ì—†ë‹¤", "ê·¸ë¦¬ê³ ",
        "ë„ˆë¬´", "ì •ë§", "ëŠë‚Œ", "ë¶„ìœ„ê¸°", "ìˆœê°„", "ì˜¤ëŠ˜", "ì´ë²ˆ", "ê·¸ëƒ¥", "ê´€ë ¨", "ê²ƒ", "ìˆ˜"
    }
    # í•œê¸€/ì˜ë¬¸ ëª…ì‚¬í˜• ë‹¨ì–´ ì¶”ì¶œ ì‹œë„
    toks = re.findall(r"[ê°€-í£A-Za-z0-9_]{2,}", text or "")
    toks = [t for t in toks if t.lower() not in STOPWORDS and not re.match(r"^\d+$", t)]
    cnt = Counter(toks)
    return ["#" + w for w, _ in cnt.most_common(k)]

def _extract_json_from_text(text: str) -> Dict[str, Any]:
    """AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (Ollama ëŒ€ë¹„ ê°•í™”)"""
    try:
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        text = re.sub(r"^\s*```(?:json)?\s*", "", text, flags=re.IGNORECASE | re.MULTILINE)
        text = re.sub(r"\s*```\s*$", "", text, flags=re.MULTILINE)
        
        # ê°€ì¥ ë°”ê¹¥ìª½ ì¤‘ê´„í˜¸ ì°¾ê¸°
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1 and end > start:
            json_str = text[start:end+1]
            return json.loads(json_str)
        else:
            # ì¤‘ê´„í˜¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ ì‹œë„
            return json.loads(text)
    except:
        return {}




# =========================================================
# [ì„¤ì •]
# =========================================================
MAX_TAGS = 6
TOPIC_N = 2


# =========================================================
# [Step 1] Vision Model - ê°œë³„ ì´ë¯¸ì§€ ì •ë°€ ë¶„ì„
# =========================================================
def analyze_single_image(image_bytes: bytes, img_id: int, user_intent: str = "") -> Dict[str, Any]:
    """
    [Step 1] ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ì •ë°€ ë¶„ì„í•˜ì—¬ ì„¤ëª…(desc)ê³¼ íƒœê·¸(tags)ë¥¼ í•¨ê»˜ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í”„ë¡¬í”„íŠ¸ëŠ” prompts/image_analysis.mdì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    prompt_template = load_prompt("image_analysis")
    prompt = render_prompt(prompt_template, {
        "user_intent": user_intent.strip() if user_intent else "(ì—†ìŒ)"
    })


    
    try:
        # â˜… UnifiedClient ì‚¬ìš©
        out = client.chat_vision(prompt, image_bytes)
        
        # ì„¤ëª… ì¶”ì¶œ
        desc = ""
        for line in out.splitlines():
            line = line.strip()
            if line.startswith("ì„¤ëª…:"):
                desc = line.replace("ì„¤ëª…:", "", 1).strip()
                break
        if not desc:
            desc = out.split("\n")[0].strip()  # fallback: ì²« ì¤„
        
        # íƒœê·¸ ì¶”ì¶œ
        tags = []
        for line in out.splitlines():
            line = line.strip()
            if line.startswith("íƒœê·¸:"):
                tag_part = line.replace("íƒœê·¸:", "", 1).strip()
                raw_tags = re.split(r'[,\s]+', tag_part)
                for t in raw_tags:
                    t = t.strip()
                    if t:
                        if not t.startswith("#"): t = "#" + t
                        t = "#" + re.sub(r'[^0-9A-Za-zê°€-í£_]', '', t.replace("#", ""))
                        if len(t) > 1 and t not in tags:
                            tags.append(t)
                break
        
        if not tags:
            tags = _extract_tags_from_text(desc, k=4)
        
        return {"img_id": img_id, "desc": desc, "tags": tags[:5]}
        
    except Exception as e:
        print(f"[ì´ë¯¸ì§€ {img_id}] ë¶„ì„ ì—ëŸ¬: {e}")
        return {"img_id": img_id, "desc": "ë¶„ì„ ì‹¤íŒ¨", "tags": ["#ì‚¬ì§„"]}


def _extract_tags_from_text(text: str, k: int = 4) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë¹ˆë„ ê¸°ë°˜ìœ¼ë¡œ íƒœê·¸ ì¶”ì¶œ (ë°±ì—…ìš©)"""
    STOPWORDS = {
        "ì‚¬ì§„", "ì´ë¯¸ì§€", "ì¥ë©´", "ì œí’ˆ", "êµ¬ì„±", "í¬í•¨", "ìˆëŠ”", "ìœ„", "ì•„ë˜", "ì˜†", "ì•", "ë’¤",
        "ê°™ì€", "ìœ„í•´", "ì •ë„", "ë¶€ë¶„", "ì‚¬ìš©", "ê°€ëŠ¥", "ë³´ì„", "ë³´ì´ëŠ”", "ìˆë‹¤", "ì—†ë‹¤", "ê·¸ë¦¬ê³ ",
        "ë„ˆë¬´", "ì •ë§", "ëŠë‚Œ", "ë¶„ìœ„ê¸°", "ìˆœê°„", "ì˜¤ëŠ˜", "ì´ë²ˆ", "ê·¸ëƒ¥", "ê´€ë ¨", "ê²ƒ", "ìˆ˜"
    }
    toks = re.findall(r"[ê°€-í£A-Za-z0-9_]{2,}", text or "")
    toks = [t for t in toks if t.lower() not in STOPWORDS and not re.match(r"^\d+$", t)]
    cnt = Counter(toks)
    return ["#" + w for w, _ in cnt.most_common(k)]


# =========================================================
# [Step 2] Text Model - ê°œë³„ ë¶„ì„ ê²°ê³¼ ì·¨í•© ë° í†µí•© ê¸°íš
# =========================================================
def aggregate_and_plan(
    individual_analyses: List[Dict[str, Any]], 
    user_intent: str = "",
    n_topics: int = TOPIC_N
) -> Dict[str, Any]:
    """
    [Step 2] ê°œë³„ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë“¤ì„ ì·¨í•©í•˜ì—¬ í†µí•© ê¸°íšì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    image_sections = []
    all_tags_pool = []
    
    for item in individual_analyses:
        img_id = item.get("img_id", "?")
        desc = item.get("desc", "")
        tags = item.get("tags", [])
        tag_str = ", ".join(tags) if tags else "(ì—†ìŒ)"
        image_sections.append(f"[ì‚¬ì§„ {img_id}]\n- ì„¤ëª…: {desc}\n- íƒœê·¸: {tag_str}")
        all_tags_pool.extend(tags)
    
    images_text = "\n\n".join(image_sections)
    tag_freq = Counter(all_tags_pool)
    frequent_tags = [t for t, _ in tag_freq.most_common(MAX_TAGS)]
    tag_hint = ", ".join(frequent_tags) if frequent_tags else "(ì—†ìŒ)"
    
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ ë¡œë“œ
    prompt_template = load_prompt("image_aggregate")
    prompt = render_prompt(prompt_template, {
        "user_intent": (user_intent or "").strip() or "(ì—†ìŒ)",
        "images_text": images_text,
        "tag_hint": tag_hint,
        "n_topics": str(n_topics),
        "max_tags": str(MAX_TAGS),
    })

    try:
        # â˜… UnifiedClient ì‚¬ìš©
        txt = client.chat_text(prompt)
        
        try:
            result = json.loads(txt)
        except json.JSONDecodeError:
            m = re.search(r"\{.*\}", txt, re.S)
            result = json.loads(m.group(0)) if m else {}
        
        # íƒœê·¸ ë³´ì •
        tags = result.get("tags", [])
        tags = [t if t.startswith("#") else "#" + t for t in tags][:MAX_TAGS]
        while len(tags) < MAX_TAGS:
            if len(frequent_tags) > len(tags):
                candidate = frequent_tags[len(tags)]
                if candidate not in tags: tags.append(candidate)
                else: tags.append(f"#íƒœê·¸{len(tags)+1}")
            else:
                tags.append(f"#íƒœê·¸{len(tags)+1}")
        result["tags"] = tags
        
        return result
        
    except Exception as e:
        print(f"[í†µí•© ê¸°íš] ì—ëŸ¬: {e}")
        return {
            "merged_description": "í†µí•© ë¶„ì„ ì‹¤íŒ¨",
            "mood": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "tags": frequent_tags[:MAX_TAGS] if frequent_tags else ["#ì‚¬ì§„", "#ê¸°ë¡"],
            "topic_candidates": [],
            "best_topic": ""
        }


# =========================================================
# [ë©”ì¸ ì§„ì…ì ] Step2ì—ì„œ í˜¸ì¶œ
# =========================================================
def analyze_image_agent(images: list, user_intent: str = "") -> str:
    """
    [ë©”ì¸ ì§„ì…ì  - Bottom-up ë°©ì‹]
    Step 2ì—ì„œ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    if not isinstance(images, list):
        images = [images]
    
    # Step 1: ê°œë³„ ë¶„ì„
    individual_analyses = []
    for idx, img_bytes in enumerate(images, start=1):
        analysis = analyze_single_image(img_bytes, img_id=idx, user_intent=user_intent)
        individual_analyses.append(analysis)
    
    # Step 2: í†µí•© ê¸°íš
    unified_result = aggregate_and_plan(
        individual_analyses=individual_analyses,
        user_intent=user_intent,
        n_topics=TOPIC_N
    )
    
    return json.dumps(unified_result, ensure_ascii=False)


def parse_image_analysis(raw_result: str):
    """ê²°ê³¼ íŒŒì‹± Helper"""
    try:
        if isinstance(raw_result, str):
            data = json.loads(raw_result)
        else:
            data = raw_result
        
        mood = data.get("mood", "")
        merged_desc = data.get("merged_description", "")
        tags = data.get("tags", [])
        
        display_text = mood if mood else merged_desc
        return display_text, tags

    except Exception as e:
        return "ë¶„ì„ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", []
